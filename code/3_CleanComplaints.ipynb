{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96da2a9",
   "metadata": {},
   "source": [
    "# Cleaning the Chicago Police Use-Of-Force Citizen Complaints Data\n",
    "#### Mihir Bhaskar\n",
    "#### 11/23/2021\n",
    "\n",
    "The following file reads in a raw .csv data file on citizen complaints of police use-of-force sourced from: https://data.cpdp.co/data/bVBkzB/ (accessed on 21st November, 2021). \n",
    "\n",
    "It performs the following tasks:\n",
    "1. Cleans, processes, and merges all the subtables in the data (i.e. on complaints, police officers, and witnesses), keeping only complaints from 2015 onwards\n",
    "2. Creates and outputs a basic dataset at the tract-level, called 'CleanComplaints', that has all tract IDs in Chicago along with the number of complaints from that tract. It does this by first doing a a spatial merge based on lat-long with the CleanACSFile data outputted from 2_CleanACS to get the tract ID for each complaint, and aggregates data up to the tract level. \n",
    "3. Creates and outputs a full granular dataset, at the complaint-officer level, called 'CleanComplaints_FindingLevel.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46d11e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5e034f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data (downloaded from website linked above as Excel file)\n",
    "\n",
    "## To-do: use Python's openpyxl library to filter the datasets before importing -> improve speed\n",
    "\n",
    "cmp = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Allegations')\n",
    "witness = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Complaining Witnesses')\n",
    "officer = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Officer Profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539d766",
   "metadata": {},
   "source": [
    "## 1. Cleaning all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410e2f6",
   "metadata": {},
   "source": [
    "### Cleaning main complaints file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31d1e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to only include complaints from 2015 onwards\n",
    "\n",
    "## There are 8 rows where incident date (what we want to filter on) is missing\n",
    "cmp['IncidentDate'].isnull().sum()\n",
    "\n",
    "## Drop cases where incidentdate is missing - these are only 8 observations, and there is no other good way\n",
    "## to tell when a complaint occured. The start date only refers to the start of the investigation, and this could be\n",
    "## very different from the actual timing of the complaint.\n",
    "cmp = cmp.dropna(subset=['IncidentDate'])\n",
    "\n",
    "## Converting incident date to a date variable\n",
    "cmp['IncidentDate']= pd.to_datetime(cmp['IncidentDate'])\n",
    "\n",
    "## Keeping only complaints >= 2015\n",
    "cmp = cmp[cmp['IncidentDate'] >= '2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba1b8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert CRID to numeric for merging with other datasets\n",
    "cmp['CRID'] = pd.to_numeric(cmp['CRID'])\n",
    "\n",
    "## Keep only useful variables\n",
    "cmp = cmp[['CRID', 'OfficerID', 'Allegation', 'Finding', 'Outcome', 'Beat', 'IncidentDate', 'StartDate', 'EndDate', 'InvestigatorRank',\n",
    "           'Latitude', 'Longitude']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec489139",
   "metadata": {},
   "source": [
    "### Cleaning officer and witness tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8072414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OfficerID</th>\n",
       "      <th>officer_gender</th>\n",
       "      <th>officer_race</th>\n",
       "      <th>officer_appt_date</th>\n",
       "      <th>officer_rank_order</th>\n",
       "      <th>officer_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>2005-09-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2005-09-26 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>1969-01-06 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>1994-12-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>1995-12-04 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OfficerID officer_gender officer_race    officer_appt_date  \\\n",
       "0          1              M        White  2005-09-26 00:00:00   \n",
       "1          2              F     Hispanic  2005-09-26 00:00:00   \n",
       "2          4              M        White  1969-01-06 00:00:00   \n",
       "3          6              M        White  1994-12-05 00:00:00   \n",
       "4          7              M        White  1995-12-04 00:00:00   \n",
       "\n",
       "   officer_rank_order  officer_age  \n",
       "0                 2.0           50  \n",
       "1                 1.0           41  \n",
       "2                 1.0           79  \n",
       "3                 1.0           53  \n",
       "4                 1.0           49  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting appointment date to correct date format\n",
    "officer['clean_appdate'] = ''\n",
    "\n",
    "officer.loc[officer['ApptDate'].notna(), 'clean_appdate'] = pd.to_datetime(officer['ApptDate'], unit='d', origin='1899-12-30')\n",
    "\n",
    "# Create an ordinal variable for officer rank (1 = police officer, 2 = sargeant, etc.)\n",
    "# Based this on Ranks section of this Wiki page: https://en.wikipedia.org/wiki/Chicago_Police_Department#Ranks\n",
    "\n",
    "# Drop officers without a rank (45 officers dropped - this also takes care of officers with other pieces of missing information)\n",
    "officer.dropna(subset=['Rank'], inplace=True)\n",
    "\n",
    "l = ['Sergeant Of Police', 'Sergeant Per Arbitra', 'Sgt', 'Sgt Assgn Sec Spec']\n",
    "regstr = '|'.join(l)\n",
    "officer.loc[officer['Rank'].str.contains(regstr), 'rank_order'] = 2\n",
    "\n",
    "l = ['Lieutenant Of Police', 'Lt']\n",
    "regstr = '|'.join(l)\n",
    "officer.loc[officer['Rank'].str.contains(regstr), 'rank_order'] = 3\n",
    "\n",
    "officer.loc[officer['Rank'] == 'Captain Of Police', 'rank_order'] = 4\n",
    "\n",
    "l = ['Commander', 'Cmdr']\n",
    "regstr = '|'.join(l)\n",
    "officer.loc[officer['Rank'].str.contains(regstr), 'rank_order'] = 5\n",
    "\n",
    "officer.loc[officer['Rank'] == 'Dep Chief', 'rank_order'] = 6\n",
    "\n",
    "officer.loc[officer['Rank'] == 'Chief', 'rank_order'] = 7\n",
    "\n",
    "l = ['Assistant Superintendent', 'Asst Deputy Sup', 'Deputy Supt.', 'First Deputy Supt.', 'Supt Of Police']\n",
    "regstr = '|'.join(l)\n",
    "officer.loc[officer['Rank'].str.contains(regstr), 'rank_order'] = 8\n",
    "\n",
    "# Put the rest of the officers as rank one\n",
    "officer['rank_order'] = officer['rank_order'].fillna(1)\n",
    "\n",
    "# Keeping only relevant info from the table\n",
    "officer = officer[['OfficerID', 'Gender', 'Race', 'clean_appdate', 'rank_order', 'Age']]\n",
    "\n",
    "# Renaming columns to keep it ready for the merge\n",
    "officer.rename(columns={'Gender':'officer_gender', 'Race': 'officer_race', 'rank_order': 'officer_rank_order', 'Age': 'officer_age',\n",
    "                      'clean_appdate': 'officer_appt_date'}, inplace=True)\n",
    "\n",
    "# Printing to check\n",
    "officer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5bdace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>witness_gender</th>\n",
       "      <th>witness_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000006</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRID witness_gender witness_race\n",
       "0  1000002              M     Hispanic\n",
       "1  1000002              M     Hispanic\n",
       "2  1000004              M     Hispanic\n",
       "3  1000004              M     Hispanic\n",
       "4  1000006              M        Black"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping witness age because it's missing for all\n",
    "witness.drop(columns=['Age'], inplace=True)\n",
    "\n",
    "## Renaming columns in witness table before merge\n",
    "\n",
    "witness.rename(columns={'Gender': 'witness_gender', 'Race': 'witness_race'}, inplace = True)\n",
    "\n",
    "witness.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0241b3",
   "metadata": {},
   "source": [
    "### Combine all data into one merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38a40433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRID', 'OfficerID', 'Allegation', 'Finding', 'Outcome', 'Beat',\n",
      "       'IncidentDate', 'StartDate', 'EndDate', 'InvestigatorRank', 'Latitude',\n",
      "       'Longitude', 'officer_gender', 'officer_race', 'officer_appt_date',\n",
      "       'officer_rank_order', 'officer_age', 'witness_gender', 'witness_race'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>OfficerID</th>\n",
       "      <th>Allegation</th>\n",
       "      <th>Finding</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Beat</th>\n",
       "      <th>IncidentDate</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>InvestigatorRank</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>officer_gender</th>\n",
       "      <th>officer_race</th>\n",
       "      <th>officer_appt_date</th>\n",
       "      <th>officer_rank_order</th>\n",
       "      <th>officer_age</th>\n",
       "      <th>witness_gender</th>\n",
       "      <th>witness_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073214</td>\n",
       "      <td>7936</td>\n",
       "      <td>Excessive Force / On Duty - No Injury</td>\n",
       "      <td>Not Sustained</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>313.0</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.781068</td>\n",
       "      <td>-87.605533</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>2012-12-14 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073237</td>\n",
       "      <td>17217</td>\n",
       "      <td>Excessive Force / On Duty - No Injury</td>\n",
       "      <td>Unfounded</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.898191</td>\n",
       "      <td>-87.720292</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2003-08-25 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073237</td>\n",
       "      <td>24563</td>\n",
       "      <td>Excessive Force / On Duty - No Injury</td>\n",
       "      <td>Unfounded</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.898191</td>\n",
       "      <td>-87.720292</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2003-09-29 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1073267</td>\n",
       "      <td>23783</td>\n",
       "      <td>Excessive Force / On Duty - No Injury</td>\n",
       "      <td>Not Sustained</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.895415</td>\n",
       "      <td>-87.719968</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1994-09-06 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1073323</td>\n",
       "      <td>21448</td>\n",
       "      <td>Excessive Force / On Duty - Injury</td>\n",
       "      <td>Unfounded</td>\n",
       "      <td>No Action Taken</td>\n",
       "      <td>932.0</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.794156</td>\n",
       "      <td>-87.672792</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1994-09-06 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRID  OfficerID                             Allegation        Finding  \\\n",
       "0  1073214       7936  Excessive Force / On Duty - No Injury  Not Sustained   \n",
       "2  1073237      17217  Excessive Force / On Duty - No Injury      Unfounded   \n",
       "4  1073237      24563  Excessive Force / On Duty - No Injury      Unfounded   \n",
       "6  1073267      23783  Excessive Force / On Duty - No Injury  Not Sustained   \n",
       "8  1073323      21448     Excessive Force / On Duty - Injury      Unfounded   \n",
       "\n",
       "           Outcome    Beat IncidentDate   StartDate     EndDate  \\\n",
       "0  No Action Taken   313.0   2015-01-03  2015-01-03  2015-04-16   \n",
       "2  No Action Taken  1112.0   2015-01-03  2015-01-05  2015-09-09   \n",
       "4  No Action Taken  1112.0   2015-01-03  2015-01-05  2015-09-09   \n",
       "6  No Action Taken  1112.0   2015-01-07  2015-01-07  2015-04-23   \n",
       "8  No Action Taken   932.0   2015-01-03  2015-01-12  2015-06-18   \n",
       "\n",
       "  InvestigatorRank   Latitude  Longitude officer_gender officer_race  \\\n",
       "0              NaN  41.781068 -87.605533              F        Black   \n",
       "2              NaN  41.898191 -87.720292              M     Hispanic   \n",
       "4              NaN  41.898191 -87.720292              M     Hispanic   \n",
       "6              NaN  41.895415 -87.719968              M     Hispanic   \n",
       "8              NaN  41.794156 -87.672792              M     Hispanic   \n",
       "\n",
       "     officer_appt_date  officer_rank_order  officer_age witness_gender  \\\n",
       "0  2012-12-14 00:00:00                 1.0         46.0              M   \n",
       "2  2003-08-25 00:00:00                 1.0         42.0              M   \n",
       "4  2003-09-29 00:00:00                 1.0         52.0              M   \n",
       "6  1994-09-06 00:00:00                 1.0         65.0              F   \n",
       "8  1994-09-06 00:00:00                 1.0         54.0              M   \n",
       "\n",
       "  witness_race  \n",
       "0        Black  \n",
       "2        White  \n",
       "4        White  \n",
       "6        Black  \n",
       "8        Black  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with the main table\n",
    "cmp_full = cmp.merge(officer, how='left', on=['OfficerID'])\n",
    "\n",
    "cmp_full = cmp_full.merge(witness, how='left', on=['CRID'])\n",
    "\n",
    "# Drop full duplicates (unsure why these are created - maybe because of duplicates in officer ID table?)\n",
    "cmp_full.drop_duplicates(inplace=True)\n",
    "\n",
    "print(cmp_full.columns)\n",
    "cmp_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135783d",
   "metadata": {},
   "source": [
    "## 2. Create a basic dataset with just # complaints per tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "744cf59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRID          0\n",
      "Latitude     22\n",
      "Longitude    22\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-0a832123fb98>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  basic_df.drop_duplicates(subset=['CRID'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop all irrelevant columns\n",
    "basic_df = cmp_full[['CRID', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Drop duplicates in CRID - in the imported data, there is a row for every officer linked with the complaint\n",
    "# For now, we are only interested in the total # of unique complaints\n",
    "basic_df.drop_duplicates(subset=['CRID'], inplace=True)\n",
    "\n",
    "# Checking the quality/missingness of lat-long data\n",
    "print(basic_df.isnull().sum()) \n",
    "\n",
    "# There are 22 missing lat-long values. We cannot merge these with the appropriate census tract,\n",
    "# so dropping these. \n",
    "# To-do code: check to see if address information is present for these missing lat-longs, and whether they can be geo-coded\n",
    "basic_df = basic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ed4b49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>geo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073214</td>\n",
       "      <td>41.781068</td>\n",
       "      <td>-87.605533</td>\n",
       "      <td>POINT (-87.60553 41.78107)</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1400000US17031420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073237</td>\n",
       "      <td>41.898191</td>\n",
       "      <td>-87.720292</td>\n",
       "      <td>POINT (-87.72029 41.89819)</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1400000US17031231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1073267</td>\n",
       "      <td>41.895415</td>\n",
       "      <td>-87.719968</td>\n",
       "      <td>POINT (-87.71997 41.89542)</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1400000US17031231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1073323</td>\n",
       "      <td>41.794156</td>\n",
       "      <td>-87.672792</td>\n",
       "      <td>POINT (-87.67279 41.79416)</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1400000US17031611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1073326</td>\n",
       "      <td>41.750469</td>\n",
       "      <td>-87.635831</td>\n",
       "      <td>POINT (-87.63583 41.75047)</td>\n",
       "      <td>783.0</td>\n",
       "      <td>1400000US17031842400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRID   Latitude  Longitude                    geometry  index_right  \\\n",
       "0   1073214  41.781068 -87.605533  POINT (-87.60553 41.78107)        435.0   \n",
       "2   1073237  41.898191 -87.720292  POINT (-87.72029 41.89819)        279.0   \n",
       "6   1073267  41.895415 -87.719968  POINT (-87.71997 41.89542)        280.0   \n",
       "8   1073323  41.794156 -87.672792  POINT (-87.67279 41.79416)        557.0   \n",
       "10  1073326  41.750469 -87.635831  POINT (-87.63583 41.75047)        783.0   \n",
       "\n",
       "                  geo_id  \n",
       "0   1400000US17031420400  \n",
       "2   1400000US17031231200  \n",
       "6   1400000US17031231500  \n",
       "8   1400000US17031611700  \n",
       "10  1400000US17031842400  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataframe to a GeoDataFrame (required for spatial merge with census tracts polygons)\n",
    "basic_df = gpd.GeoDataFrame(basic_df, geometry=gpd.points_from_xy(basic_df.Longitude, basic_df.Latitude), crs='epsg:4326')\n",
    "\n",
    "# Importing the census tracts data and converting it to a GeoDataFrame\n",
    "acs = pd.read_csv(here('./data/CleanACSFile.csv'))\n",
    "\n",
    "# Keeping only relevant info from acs file for the spatial merge\n",
    "acs = acs[['geo_id', 'geometry']]\n",
    "\n",
    "acs['geometry'] = acs['geometry'].apply(wkt.loads)\n",
    "acs = gpd.GeoDataFrame(acs, crs='epsg:4326')\n",
    "\n",
    "# Doing the spatial merge to assign a tract ID to every complaint\n",
    "basic_df = gpd.sjoin(basic_df, acs[['geo_id', 'geometry']], how='left')\n",
    "\n",
    "basic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe2ef86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRID            0\n",
      "Latitude        0\n",
      "Longitude       0\n",
      "geometry        0\n",
      "index_right    20\n",
      "geo_id         20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking how many observations did not match to a tract ID\n",
    "print(basic_df.isnull().sum()) # 20 observations did not find a census tract match\n",
    "\n",
    "basic_df[basic_df['geo_id'].isnull()]\n",
    "\n",
    "# Note: manuall checking these lat-longs, it appears that these are valid-latlongs, but fall\n",
    "# outside of the City of Chicago boundaries. E.g., CRID 1074942 was from Oak Lawn, which falls to the west of the boundaries\n",
    "\n",
    "# Since these are outside of the focus area of the study (City of Chicago), we are dropping these 20 observations\n",
    "basic_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1eb4fbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>complaint_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400000US17031010100</td>\n",
       "      <td>MULTIPOLYGON (((-87.67720 42.02294, -87.67007 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US17031010201</td>\n",
       "      <td>MULTIPOLYGON (((-87.68465 42.01949, -87.68045 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US17031010202</td>\n",
       "      <td>MULTIPOLYGON (((-87.67685 42.01941, -87.67339 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US17031010300</td>\n",
       "      <td>MULTIPOLYGON (((-87.67133 42.01937, -87.66950 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US17031010400</td>\n",
       "      <td>MULTIPOLYGON (((-87.66345 42.01283, -87.66133 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 geo_id                                           geometry  \\\n",
       "0  1400000US17031010100  MULTIPOLYGON (((-87.67720 42.02294, -87.67007 ...   \n",
       "1  1400000US17031010201  MULTIPOLYGON (((-87.68465 42.01949, -87.68045 ...   \n",
       "2  1400000US17031010202  MULTIPOLYGON (((-87.67685 42.01941, -87.67339 ...   \n",
       "3  1400000US17031010300  MULTIPOLYGON (((-87.67133 42.01937, -87.66950 ...   \n",
       "4  1400000US17031010400  MULTIPOLYGON (((-87.66345 42.01283, -87.66133 ...   \n",
       "\n",
       "   complaint_count  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              1.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping by the census ID to create a count of crime IDs for each tract\n",
    "counts = basic_df[['CRID', 'geo_id']].groupby('geo_id').count()\n",
    "\n",
    "# Merging these counts back with the full dataset of census tract IDs\n",
    "merged = acs.merge(counts, how='left', on=['geo_id'])\n",
    "\n",
    "# Replacing missing crime ID count values with 0 (i.e. missing means there were 0 complaints found in that tract)\n",
    "merged['CRID'] = merged['CRID'].fillna(0)\n",
    "\n",
    "# Renaming column\n",
    "merged.rename(columns={'CRID':'complaint_count'}, inplace=True)\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0300f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export .CSV file to be used in other scripts\n",
    "merged[['geo_id', 'complaint_count']].to_csv(here('./data/CleanComplaints.csv'),\n",
    "                                            encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1edcf",
   "metadata": {},
   "source": [
    "## 3. Create and explort a more detailed finding-level dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dd65d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmp_full.head()\n",
    "\n",
    "'''\n",
    "To-dos:\n",
    "- process allegation data into categories (group them into types)\n",
    "- create officer vintage variable\n",
    "- Extract incident year \n",
    "'''\n",
    "\n",
    "# Spatially merging tract-id on these complaints so we can do merges with more features later\n",
    "cmp_full = cmp_full.merge(basic_df, how='left', on=['CRID'])\n",
    "\n",
    "cmp_full.columns\n",
    "\n",
    "# Create variable on how long the officer had been employed for at the time of the incident\n",
    "#cmp_full['officer_vintage'] = cmp_full['IncidentDate'] - cmp_full['officer_appt_date'] \n",
    "\n",
    "#cmp_full.head()\n",
    "\n",
    "#type(cmp_full['officer_appt_date'][0])\n",
    "\n",
    "## Exporting this full dataset to be read into Question 2\n",
    "cmp_full.to_csv(here('./data/CleanComplaints_FindingLevel.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269d80e",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Code sourced:\n",
    "- https://stackoverflow.com/questions/38454403/convert-excel-style-date-with-pandas\n",
    "- https://www.geeksforgeeks.org/python-convert-excel-serial-date-to-datetime/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "507b1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Archive code that could be used/repurposed later\n",
    "\n",
    "# Seeing the proportion of complaints that were sustained\n",
    "\n",
    "#cmp.drop_duplicates(subset=['CRID'], inplace=True)\n",
    "\n",
    "# cmp[['CRID', 'Finding']].groupby('Finding').count()\n",
    "\n",
    "## Dropping irrelevant columns\n",
    "#officers.drop(['OfficerFirst', 'OfficerLast'])\n",
    "\n",
    "## Renaming variables before merging on CRID\n",
    "#officers.columns = ['CRID', '']\n",
    "\n",
    "## Dropping irrelevant columns\n",
    "#complaints.drop(['OfficeFirst', 'OfficerLast', 'AllegationCode', 'RecommendedFinding', 'RecommendedOutcome',\n",
    "#                'FinalFinding', 'FinalOutcome', ''], axis=1)\n",
    "\n",
    "## Drop irrelevant columns, merge the info across the three datasets\n",
    "#print(complaints.info(), '\\n', comp_witness.info(), '\\n', officers.info())\n",
    "\n",
    "#cmp.head()\n",
    "\n",
    "#cmp[['Beat', 'Location', 'City']].head(100)\n",
    "\n",
    "#cmp['Diff'] = np.where(cmp['RecommendedFinding'] == cmp['FinalFinding'], 1, 0)\n",
    "\n",
    "#cmp['Diff'].mean()\n",
    "\n",
    "## The unique ID here is CRID and officerID\n",
    "## Drop the unnecessary columns, merge the good columns from the other datasets, then describe the missingness and uniqueness \n",
    "\n",
    "#cmp.describe()\n",
    "#cmp.info()\n",
    "\n",
    "#cmp.nunique(axis=0)\n",
    "\n",
    "#cmp[cmp['CRID'] == '1090030']\n",
    "\n",
    "#cmp['uid'] = cmp['CRID'] + (cmp['OfficerID']).astype(str)\n",
    "\n",
    "#cmp.nunique(axis=0)\n",
    "\n",
    "\n",
    "#dups = cmp[cmp.duplicated(['CRID'])].sort_values('CRID')\n",
    "\n",
    "#dups.head(100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
