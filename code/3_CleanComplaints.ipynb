{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96da2a9",
   "metadata": {},
   "source": [
    "# Cleaning the Chicago Police Use-Of-Force Citizen Complaints Data\n",
    "#### Mihir Bhaskar\n",
    "#### 11/23/2021\n",
    "\n",
    "The following file reads in a raw .csv data file on citizen complaints of police use-of-force sourced from: https://data.cpdp.co/data/bVBkzB/ (accessed on 21st November, 2021). \n",
    "\n",
    "The code then processes the data (e.g. by keeping only data from 2015 onwards), does a spatial merge based on lat-long with the CleanACSFile data outputted from 2_CleanACS to get the tract ID for each complaint, and aggregates data up to the tract level. \n",
    "\n",
    "It then exports a .csv file called 'CleanComplaints', which has all the tract IDs in Chicago, along with columns relating to the number of complaints (e.g. total # of complaints received from that tract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d11e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e034f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data (downloaded from website linked above as Excel file)\n",
    "\n",
    "## To-do: use Python's openpyxl library to filter the datasets before importing -> improve speed\n",
    "\n",
    "cmp = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Allegations')\n",
    "witness = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Complaining Witnesses')\n",
    "officer = pd.read_excel(here('./data/raw/uof_complaints_chicago.xlsx'), sheet_name='Officer Profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed88f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d1e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to only include complaints from 2015 onwards\n",
    "\n",
    "## There are 8 rows where incident date (what we want to filter on) is missing\n",
    "cmp['IncidentDate'].isnull().sum()\n",
    "\n",
    "## Drop cases where incidentdate is missing - these are only 8 observations, and there is no other good way\n",
    "## to tell when a complaint occured. The start date only refers to the start of the investigation, and this could be\n",
    "## very different from the actual timing of the complaint.\n",
    "cmp = cmp.dropna(subset=['IncidentDate'])\n",
    "\n",
    "## Converting incident date to a date variable\n",
    "cmp['Date']= pd.to_datetime(cmp['IncidentDate'])\n",
    "\n",
    "## Keeping only complaints >= 2015\n",
    "cmp = cmp[cmp['Date'] >= '2015-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135783d",
   "metadata": {},
   "source": [
    "## Create a basic dataset with # complaints per tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744cf59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRID          0\n",
      "Latitude     22\n",
      "Longitude    22\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacar\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Drop all irrelevant columns\n",
    "basic_df = cmp[['CRID', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Drop duplicates in CRID - in the imported data, there is a row for every officer linked with the complaint\n",
    "# For now, we are only interested in the total # of unique complaints\n",
    "basic_df.drop_duplicates(subset=['CRID'], inplace=True)\n",
    "\n",
    "# Checking the quality/missingness of lat-long data\n",
    "print(basic_df.isnull().sum()) \n",
    "\n",
    "# There are 22 missing lat-long values. We cannot merge these with the appropriate census tract,\n",
    "# so dropping these. \n",
    "# To-do code: check to see if address information is present for these missing lat-longs, and whether they can be geo-coded\n",
    "basic_df = basic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed4b49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>geo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55436</th>\n",
       "      <td>1073214</td>\n",
       "      <td>41.781068</td>\n",
       "      <td>-87.605533</td>\n",
       "      <td>POINT (-87.60553 41.78107)</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1400000US17031420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55439</th>\n",
       "      <td>1073237</td>\n",
       "      <td>41.898191</td>\n",
       "      <td>-87.720292</td>\n",
       "      <td>POINT (-87.72029 41.89819)</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1400000US17031231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55447</th>\n",
       "      <td>1073267</td>\n",
       "      <td>41.895415</td>\n",
       "      <td>-87.719968</td>\n",
       "      <td>POINT (-87.71997 41.89542)</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1400000US17031231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55453</th>\n",
       "      <td>1073323</td>\n",
       "      <td>41.794156</td>\n",
       "      <td>-87.672792</td>\n",
       "      <td>POINT (-87.67279 41.79416)</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1400000US17031611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55454</th>\n",
       "      <td>1073326</td>\n",
       "      <td>41.750469</td>\n",
       "      <td>-87.635831</td>\n",
       "      <td>POINT (-87.63583 41.75047)</td>\n",
       "      <td>783.0</td>\n",
       "      <td>1400000US17031842400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRID   Latitude  Longitude                    geometry  index_right  \\\n",
       "55436  1073214  41.781068 -87.605533  POINT (-87.60553 41.78107)        435.0   \n",
       "55439  1073237  41.898191 -87.720292  POINT (-87.72029 41.89819)        279.0   \n",
       "55447  1073267  41.895415 -87.719968  POINT (-87.71997 41.89542)        280.0   \n",
       "55453  1073323  41.794156 -87.672792  POINT (-87.67279 41.79416)        557.0   \n",
       "55454  1073326  41.750469 -87.635831  POINT (-87.63583 41.75047)        783.0   \n",
       "\n",
       "                     geo_id  \n",
       "55436  1400000US17031420400  \n",
       "55439  1400000US17031231200  \n",
       "55447  1400000US17031231500  \n",
       "55453  1400000US17031611700  \n",
       "55454  1400000US17031842400  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataframe to a GeoDataFrame (required for spatial merge with census tracts polygons)\n",
    "basic_df = gpd.GeoDataFrame(basic_df, geometry=gpd.points_from_xy(basic_df.Longitude, basic_df.Latitude), crs='epsg:4326')\n",
    "\n",
    "# Importing the census tracts data and converting it to a GeoDataFrame\n",
    "acs = pd.read_csv(here('./data/CleanACSFile.csv'))\n",
    "\n",
    "# Keeping only relevant info from acs file for the spatial merge\n",
    "acs = acs[['geo_id', 'geometry']]\n",
    "\n",
    "acs['geometry'] = acs['geometry'].apply(wkt.loads)\n",
    "acs = gpd.GeoDataFrame(acs, crs='epsg:4326')\n",
    "\n",
    "# Doing the spatial merge to assign a tract ID to every complaint\n",
    "basic_df = gpd.sjoin(basic_df, acs[['geo_id', 'geometry']], how='left')\n",
    "\n",
    "basic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2ef86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRID            0\n",
      "Latitude        0\n",
      "Longitude       0\n",
      "geometry        0\n",
      "index_right    20\n",
      "geo_id         20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking how many observations did not match to a tract ID\n",
    "print(basic_df.isnull().sum()) # 20 observations did not find a census tract match\n",
    "\n",
    "basic_df[basic_df['geo_id'].isnull()]\n",
    "\n",
    "# Note: manuall checking these lat-longs, it appears that these are valid-latlongs, but fall\n",
    "# outside of the City of Chicago boundaries. E.g., CRID 1074942 was from Oak Lawn, which falls to the west of the boundaries\n",
    "\n",
    "# Since these are outside of the focus area of the study (City of Chicago), we are dropping these 20 observations\n",
    "basic_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb4fbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>complaint_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400000US17031010100</td>\n",
       "      <td>MULTIPOLYGON (((-87.67720 42.02294, -87.67007 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US17031010201</td>\n",
       "      <td>MULTIPOLYGON (((-87.68465 42.01949, -87.68045 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US17031010202</td>\n",
       "      <td>MULTIPOLYGON (((-87.67685 42.01941, -87.67339 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US17031010300</td>\n",
       "      <td>MULTIPOLYGON (((-87.67133 42.01937, -87.66950 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US17031010400</td>\n",
       "      <td>MULTIPOLYGON (((-87.66345 42.01283, -87.66133 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 geo_id                                           geometry  \\\n",
       "0  1400000US17031010100  MULTIPOLYGON (((-87.67720 42.02294, -87.67007 ...   \n",
       "1  1400000US17031010201  MULTIPOLYGON (((-87.68465 42.01949, -87.68045 ...   \n",
       "2  1400000US17031010202  MULTIPOLYGON (((-87.67685 42.01941, -87.67339 ...   \n",
       "3  1400000US17031010300  MULTIPOLYGON (((-87.67133 42.01937, -87.66950 ...   \n",
       "4  1400000US17031010400  MULTIPOLYGON (((-87.66345 42.01283, -87.66133 ...   \n",
       "\n",
       "   complaint_count  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              1.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping by the census ID to create a count of crime IDs for each tract\n",
    "counts = basic_df[['CRID', 'geo_id']].groupby('geo_id').count()\n",
    "\n",
    "# Merging these counts back with the full dataset of census tract IDs\n",
    "merged = acs.merge(counts, how='left', on=['geo_id'])\n",
    "\n",
    "# Replacing missing crime ID count values with 0 (i.e. missing means there were 0 complaints found in that tract)\n",
    "merged['CRID'] = merged['CRID'].fillna(0)\n",
    "\n",
    "# Renaming column\n",
    "merged.rename(columns={'CRID':'complaint_count'}, inplace=True)\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0300f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export .CSV file to be used in other scripts\n",
    "merged[['geo_id', 'complaint_count']].to_csv(here('./data/CleanComplaints.csv'),\n",
    "                                            encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507b1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Archive code that could be used/repurposed later\n",
    "\n",
    "## Dropping irrelevant columns\n",
    "#officers.drop(['OfficerFirst', 'OfficerLast'])\n",
    "\n",
    "## Renaming variables before merging on CRID\n",
    "#officers.columns = ['CRID', '']\n",
    "\n",
    "## Dropping irrelevant columns\n",
    "#complaints.drop(['OfficeFirst', 'OfficerLast', 'AllegationCode', 'RecommendedFinding', 'RecommendedOutcome',\n",
    "#                'FinalFinding', 'FinalOutcome', ''], axis=1)\n",
    "\n",
    "## Drop irrelevant columns, merge the info across the three datasets\n",
    "#print(complaints.info(), '\\n', comp_witness.info(), '\\n', officers.info())\n",
    "\n",
    "#cmp.head()\n",
    "\n",
    "#cmp[['Beat', 'Location', 'City']].head(100)\n",
    "\n",
    "#cmp['Diff'] = np.where(cmp['RecommendedFinding'] == cmp['FinalFinding'], 1, 0)\n",
    "\n",
    "#cmp['Diff'].mean()\n",
    "\n",
    "## The unique ID here is CRID and officerID\n",
    "## Drop the unnecessary columns, merge the good columns from the other datasets, then describe the missingness and uniqueness \n",
    "\n",
    "#cmp.describe()\n",
    "#cmp.info()\n",
    "\n",
    "#cmp.nunique(axis=0)\n",
    "\n",
    "#cmp[cmp['CRID'] == '1090030']\n",
    "\n",
    "#cmp['uid'] = cmp['CRID'] + (cmp['OfficerID']).astype(str)\n",
    "\n",
    "#cmp.nunique(axis=0)\n",
    "\n",
    "\n",
    "#dups = cmp[cmp.duplicated(['CRID'])].sort_values('CRID')\n",
    "\n",
    "#dups.head(100)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
