{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b328bf",
   "metadata": {},
   "source": [
    "# Reducing Dimensionality of our Dataset\n",
    "#### Jameson Carter\n",
    "#### 11/23/2021\n",
    "The geographic dataset obtained in getACS.py has almost 100 variables, and the additional datasets we add on have many more. This code uses PCA analysis to reduce the dimensionality of our dataset and reduce collinearity, using scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e0ac8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df2038ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/jacar/OneDrive/Documents/chicago-complaints/data/CleanACSFile.csv')\n",
    "subs = data.iloc[:,1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6aa4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(subs)\n",
    "scaledSubs=scaler.transform(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bff21c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "From https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "The below parameter is set to 0.95 so that we find the minimum number of principal components such that 95% \n",
    "of the variance is retained.\n",
    "\n",
    "Additionally, we should only run this over the training set\n",
    "'''\n",
    "pca = PCA(0.95)\n",
    "\n",
    "pca.fit(scaledSubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb81f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26032161 0.15591193 0.07721338 0.06144034 0.03462104 0.02538851\n",
      " 0.01974157 0.01925613 0.01566156 0.01490449 0.01384048 0.01275787\n",
      " 0.01226599 0.01188697 0.01155161 0.01124152 0.01072784 0.01035551\n",
      " 0.01012716 0.00997435 0.00993622 0.0096353  0.00921214 0.00891387\n",
      " 0.00833757 0.00799187 0.00761395 0.00750292 0.00731826 0.00674172\n",
      " 0.00648514 0.00621723 0.00610689 0.00597989 0.00578109 0.00558876\n",
      " 0.00521242 0.00473914 0.004476   0.00433764 0.00415546 0.0040934\n",
      " 0.00372599 0.00327582]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_) # The model kept 48 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38b527b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39228024",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train = pca.transform(train)\n",
    "test = pca.transform(test)\n",
    "'''\n",
    "lm = LinearRegression() # Then you directly apply those transformed frames here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd53e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
